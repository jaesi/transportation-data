
### 백프레셔(Backpressure)
- 소비 속도 < 생산 속도일 때, 생산을 억제해서 시스템이 터지지 않게 하는 메커니즘
- 예시) 다운로드 작업을 무한히 쌓지말고 동시에 N개만 돌리기

## 분산 실행(Distributed Execution)
## 관련 용어
### 노드
- 분산 시스템을 구성하는 물리적·논리적인 작업 단위
- 하나의 서버, 가상 머신, 컨테이너, 혹은 그 안에 들어있는 프로세스가 될 수 있음
- 작업을 실제로 수행하는 컴퓨팅 단위

### 단일 엔트리(Entry Point)
- 사용자가 한 명령만 알면 전부 수행되는 진입점
- 예: ```python -m src.main run ...```
- 장점: 심사 및 운영이 쉬우며, 문서 간결, 자동화에 유리함

### 큐 
- FIFO(First In First Out)

### dbt
- data build tool
- SQL-first 변환 엔진
- SQL(또는 Jinja‑templated SQL) 로 데이터 변환(model), 테스트(quality checks), 문서화(schema.yml), 버전 관리(Git) 를 한 번에 할 수 있게 해 주는 데이터 모델링 프레임워크

## 데이터 정형화 · 정규화 · 비정규화

### 데이터 정규화 Data Normalization
- 데이터를 일관되고 효율적인 형태로 변환해, 중복·오류·비효율을 최소화하고, 활용·분석이 쉽도록 만드는 일
- 관계형 데이터베이스 설계와 머신러닝·통계분석에서 활용됨

### 데이터 정규화 필요 이유
- 데이터 중복 문제를 해결함(PK, FK)
- 불필요한 조인·스캔을 줄여 IO감소

### 정규형(Normal Form) 정의와 단계
|정규형|핵심 조건|목적|예시(학생-수강 테이블)|
|--|--|--|--|
|제1정규형(1NF)|모든 컬럼이 원자값(스칼라)이어야 함. 중복 컬럼·배열 금지.|중복된 다중값을 없애고 행·열 구조를 깔끔히 함.|수강목록 컬럼에 “수학, 영문” → 수강목록을 별도 행(학생‑과목) 으로 분리|
|제2정규형(1NF)|1NF + 모든 비키 컬럼이 전체 기본키에 완전 함수 종속이어야 함. 부분 종속 금지)|기본키의 일부분에만 의존하는 컬럼을 별도 테이블로 분리.|학생ID, 과목ID가 복합키인 경우 학생이름이 학생ID에만 의존 → 학생 테이블로 분리|
|제3정규형(1NF)|2NF + 비키 컬럼이 다른 비키 컬럼에 종속되지 않음 (이행 종속 금지)|전이적 종속을 없애서 데이터 중복을 최소화.|학과코드 → 학과명이 학생 테이블에 존재 → 학과 테이블로 분리|
|보이스-코드 정규형(BCNF)|모든 결정자가 후보키이어야 함.|3NF보다 강한 제약으로 키와 종속 관계를 완전히 정리.|교수ID → 담당학과와 학과코드 → 담당교수가 동시에 존재할 때 충돌을 해소.|
|제4정형(4NF)|다치 종속(MVD)이 없도록 함.|한 테이블에 다중 독립적 다대다 관계가 존재할 때 분리.||
|제5정형(5NF)|조인 종속성이 없도록 함.|복잡한 조인으로만 복원 가능한 경우를 방지.||

## 데이터 거버넌스
- 조직 내 데이터 자산을 일관되고, 신뢰할 수 있으며, 안전하게 활용하도록 정책·프로세스·역할·기술을 체계화하는 일련의 관리 활동
- 핵심 목표: 데이터 품질, 데이터 보안·프라이버시, 데이터 가용성·재사용, 법적·규제 준수

## 데이터레이크와 데이터웨어하우스
### 데이터레이크
### 데이터웨어하우스
| 특성       | 데이터레이크                                                               | 데이터웨어하우스                                                               |
|----------|----------------------------------------------------------------------|------------------------------------------------------------------------|
| 주요목적     | 원시·다양한 형식(구조화, 반구조화, 비정형) 데이터를 대량 저장하고, 필요 시 쿼리·분석                   | 정형·정규화된 비즈니스 데이터(거래, 보고, BI)를 고성능으로 쿼리·집계                              |
| 스토리지     | 파일 기반 (S3, ADLS, GCS) – 오브젝트 스토리지 포맷: Parquet, ORC, Avro, JSON, CSV  | 컬럼형 DB (Snowflake, Redshift, BigQuery, Synapse) 전용 스토리지와 자동 파티셔닝/클러스터링 |
| 스키마      | 스키마‑온‑리드(읽을 때 정의) – 데이터는 그대로 적재                                      | 스키마‑온‑쓰기 – 적재 시 스키마 강제 (DDL)                                           |
| 데이터 정형화  | 정형화(정규/비정규 구분 없이) 원시 로그·이미지·동영상 등 모두 저장                              | 정규화/비정규화된 테이블 구조, 관계형 메타데이터                                            |
| 쿼리 엔진    | SQL‑on‑Hadoop/Presto/Trino, Spark, Hive 등 대용량 파일 스캔 필요               | 네이티브 쿼리 엔진(Snowflake, BigQuery) – 자동 push‑down, MPP                    |
| 성능 · 비용  | 저비용 대용량 저장, 읽기 비용이 높을 수 있음 (전체 스캔)                                   | 고성능 (컬럼형 압축, 자동 파티셔닝) – 쿼리당 비용이 낮음                                     |
| 데이터 거버넌스 | 메타데이터 카탈로그 (AWS Glue, Hive Metastore, Unity Catalog) 거버넌스·보안은 별도 레이어 | 내장 카탈로그, 역할‑기반 접근 제어, 시간 여행(Snowflake Time Travel)                     |
| 사용 사례    | • 원시 로그, IoT, 이미지·비디오, 머신러닝 피처 저장 <br> • 데이터 사이언스 탐색·프리‑프로세싱         | • KPI·대시보드, 재무·영업 보고, 복잡한 OLAP 분석 <br>• 고정 스키마·정형 비즈니스 로직              |
| 운영 모델    | 넓은 “수집‑저장” 단계 → 이후 ELT 혹은 Spark/Presto 로 변환 데이터 파이프라인에서 스테이징 레이어 역할  | 정제·모델링·집계 단계가 명확히 정의된 BI‑중심 워크로드|
| 데이터 수명   | 무제한(원시 데이터 보관) → “골든 레코드”까지 유지 가능| 보존 정책(보통 2~5년) – 비용 절감 위해 오래된 파티션 삭제/아카이브|

## ETL
- ETL이란 다양한 원천(Source)로부터 추출(Extract)하고, 비즈니스 로직, 품질 및 형식에 맞게 변환(Transform)한 뒤, 목표 저장소로 적재(Load)하는 일련의 프로세스
- 목표: 깨끗하고 일관된 데이터 확보

### Extract
| 구분        | 내용 | 구현 팁/도구 |
|-----------|----|---------|
| 대상        |||
| 추출방식      |||
| 배치 vs 실시간 |||
| 성능 및 신뢰성  |||
| 보안        |||

### Transform

### Load


### 데이터 라인리지(Data Lineage)
- 데이터가 어디서 왔고, 어떻게 변형 및 이동했는지 추적 및 시각화한 것